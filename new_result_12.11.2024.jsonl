{"setting": "attention_weight", "task": "task242_tweetqa_classification.json", "added_weigth": 0.0, "attn_accuracy": 0.8278278278278278}
{"setting": "attention_weight", "task": "task242_tweetqa_classification.json", "added_weigth": 1.0, "attn_accuracy": 0.8251584918251585}
{"setting": "attention_weight", "task": "task242_tweetqa_classification.json", "added_weigth": 2.0, "attn_accuracy": 0.8254921588254922}
{"setting": "attention_weight", "task": "task242_tweetqa_classification.json", "added_weigth": 4.0, "attn_accuracy": 0.8294961628294961}
{"setting": "attention_weight", "task": "task242_tweetqa_classification.json", "added_weigth": 8.0, "attn_accuracy": 0.7874541207874541}
{"setting": "attention_weight", "task": "task274_overruling_legal_classification.json", "added_weigth": 0.0, "attn_accuracy": 0.7687813021702838}
{"setting": "attention_weight", "task": "task274_overruling_legal_classification.json", "added_weigth": 1.0, "attn_accuracy": 0.7888146911519198}
{"setting": "attention_weight", "task": "task274_overruling_legal_classification.json", "added_weigth": 2.0, "attn_accuracy": 0.7863105175292153}
{"setting": "attention_weight", "task": "task274_overruling_legal_classification.json", "added_weigth": 4.0, "attn_accuracy": 0.6227045075125208}
{"setting": "attention_weight", "task": "task274_overruling_legal_classification.json", "added_weigth": 8.0, "attn_accuracy": 0.48080133555926546}
{"setting": "attention_weight", "task": "task1447_drug_extraction_ade.json", "added_weigth": 0.0, "attn_accuracy": 0.8955114054451803}
{"setting": "attention_weight", "task": "task1447_drug_extraction_ade.json", "added_weigth": 1.0, "attn_accuracy": 0.9036055923473142}
{"setting": "attention_weight", "task": "task1447_drug_extraction_ade.json", "added_weigth": 2.0, "attn_accuracy": 0.9065489330389993}
{"setting": "attention_weight", "task": "task1447_drug_extraction_ade.json", "added_weigth": 4.0, "attn_accuracy": 0.7954378219278881}
{"setting": "attention_weight", "task": "task1447_drug_extraction_ade.json", "added_weigth": 8.0, "attn_accuracy": 0.4952170713760118}
{"setting": "attention_weight", "task": "task936_defeasible_nli_snli_classification.json", "added_weigth": 0.0, "attn_accuracy": 0.6076923076923076}
{"setting": "attention_weight", "task": "task936_defeasible_nli_snli_classification.json", "added_weigth": 1.0, "attn_accuracy": 0.6150769230769231}
{"setting": "attention_weight", "task": "task936_defeasible_nli_snli_classification.json", "added_weigth": 2.0, "attn_accuracy": 0.6264615384615385}
{"setting": "attention_weight", "task": "task936_defeasible_nli_snli_classification.json", "added_weigth": 4.0, "attn_accuracy": 0.6396923076923077}
{"setting": "attention_weight", "task": "task936_defeasible_nli_snli_classification.json", "added_weigth": 8.0, "attn_accuracy": 0.6449230769230769}
{"setting": "attention_weight", "task": "task935_defeasible_nli_atomic_classification.json", "added_weigth": 0.0, "attn_accuracy": 0.6092307692307692}
{"setting": "attention_weight", "task": "task935_defeasible_nli_atomic_classification.json", "added_weigth": 1.0, "attn_accuracy": 0.6255384615384615}
{"setting": "attention_weight", "task": "task935_defeasible_nli_atomic_classification.json", "added_weigth": 2.0, "attn_accuracy": 0.6375384615384615}
{"setting": "attention_weight", "task": "task935_defeasible_nli_atomic_classification.json", "added_weigth": 4.0, "attn_accuracy": 0.6578461538461539}
{"setting": "attention_weight", "task": "task935_defeasible_nli_atomic_classification.json", "added_weigth": 8.0, "attn_accuracy": 0.6532307692307693}
